poor:
machine learning
cristina lopes
master of software engineering
stacy braham
computer science
5th
but
2020 spring
a
information retrieval

well:
ACM
UCI
irvine
ICS
2006
computer
september
spring
winter
fall


File Splitting: To speed up the search, I've split the files into 26 separate files, each corresponding to the first
character of the token. This way, the search engine doesn't need to scan through all tokens but only the relevant ones, resulting in faster search times.

Consideration of Important Words: The system also considers the 'importantWords.json' file. If a token is an important
word according to this file, its weight increases using the formula tf_idf *= 1 + math.log(freq). This adjustment helps
emphasize the importance of certain words in the ranking of search results.

Common Words Optimization: Common words are loaded into memory at the initialization of the search engine. This strategy
improves the performance of searching for these frequently used words.

Term Frequency-Inverse Document Frequency (TF-IDF): I've incorporated a scoring model that uses TF-IDF, a common metric
in information retrieval to determine how important a word is to a document in a collection.


